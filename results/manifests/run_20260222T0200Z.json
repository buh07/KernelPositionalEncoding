{
  "timestamp": "2026-02-22T07:40:11.428733Z",
  "git_sha": null,
  "entries": [
    {
      "stage": "deps",
      "command": "./scripts/setup_env.sh",
      "status": "ok",
      "notes": "Editable install + dependency refresh"
    },
    {
      "stage": "deps",
      "command": "python - <<'PY' import pandas, pyarrow; print('ok') PY",
      "status": "ok",
      "notes": "Verified parquet deps"
    },
    {
      "stage": "tokenize",
      "command": "python experiment1/run.py tokenize --model all --dataset all --seq-len all --cleanup-legacy",
      "status": "ok",
      "notes": "Regenerated 36 JSONL + manifests"
    },
    {
      "stage": "tokenize",
      "command": "python scripts/check_tokenized_manifest.py",
      "status": "ok",
      "notes": "[manifest-check] OK"
    },
    {
      "stage": "track-a",
      "command": "CUDA_VISIBLE_DEVICES=3 python experiment1/run.py track-a --model gpt2-small --dataset synthetic_random --seq-len 256 --limit-seqs 2 --device cuda",
      "status": "ok",
      "notes": ""
    },
    {
      "stage": "track-a",
      "command": "CUDA_VISIBLE_DEVICES=3 python experiment1/run.py track-a --model gpt2-medium --dataset synthetic_random --seq-len 256 --limit-seqs 2 --device cuda",
      "status": "ok",
      "notes": ""
    },
    {
      "stage": "track-a",
      "command": "CUDA_VISIBLE_DEVICES=3 python experiment1/run.py track-a --model olmo-1b --dataset synthetic_random --seq-len 256 --limit-seqs 2 --device cuda",
      "status": "ok",
      "notes": ""
    },
    {
      "stage": "track-a",
      "command": "CUDA_VISIBLE_DEVICES=3 python experiment1/run.py track-a --model llama-3.2-1b --dataset synthetic_random --seq-len 256 --limit-seqs 2 --device cuda",
      "status": "ok",
      "notes": ""
    },
    {
      "stage": "track-a",
      "command": "CUDA_VISIBLE_DEVICES=3 python experiment1/run.py track-a --model tinyllama-1.1b --dataset synthetic_random --seq-len 256 --limit-seqs 2 --device cuda",
      "status": "ok",
      "notes": ""
    },
    {
      "stage": "track-a",
      "command": "CUDA_VISIBLE_DEVICES=3 python experiment1/run.py track-a --model tinyllama-nope-1.1b --dataset synthetic_random --seq-len 256 --limit-seqs 2 --device cuda",
      "status": "ok",
      "notes": "positional invariance warning logged"
    },
    {
      "stage": "track-a",
      "command": "CUDA_VISIBLE_DEVICES=3 python experiment1/run.py track-a --model gpt2-small --dataset wiki40b_en_pre2019 --seq-len 256 --device cuda",
      "status": "ok",
      "notes": "100 eval sequences, heatmaps saved"
    },
    {
      "stage": "track-a",
      "command": "CUDA_VISIBLE_DEVICES=3 python experiment1/run.py track-a --model olmo-1b --dataset wiki40b_en_pre2019 --seq-len 1024 --device cuda",
      "status": "ok",
      "notes": ""
    },
    {
      "stage": "track-b",
      "command": "python experiment1/run.py track-b --model gpt2-small --dataset wiki40b_en_pre2019 --seq-len 256 --device cpu",
      "status": "ok",
      "notes": "centering+eval complete, gram saved"
    },
    {
      "stage": "tests",
      "command": "pytest tests/test_metrics.py",
      "status": "ok",
      "notes": ""
    }
  ]
}